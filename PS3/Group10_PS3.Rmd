Created by: 
Marco Hafid - 22-620-546
Matus Kubla - 23-604-382


Importing libraries
```{r}
library(class)
library(pracma)
```
Question 1:

Defining the functions
```{r}
calculate_distance <- function(point1, point2, p = 2) {
  sum(abs(point1 - point2)^p)^(1/p)
}

# Function to predict the class of a test point using kNN
knn_predict <- function(train_data, train_labels, test_point, k = 3, p = 2) {
  distances <- apply(train_data, 1, function(train_point) calculate_distance(train_point, test_point, p))
  nearest_neighbors <- order(distances)[1:k]
  nearest_labels <- train_labels[nearest_neighbors]
  predicted_class <- as.numeric(names(sort(table(nearest_labels), decreasing = TRUE)[1]))
  return(predicted_class)
}

# Function to evaluate the classification accuracy
evaluate_accuracy <- function(train_data, train_labels, test_data, test_labels, k = 3, p = 2) {
  predictions <- sapply(1:nrow(test_data), function(i) knn_predict(train_data, train_labels, test_data[i, ], k, p))
  accuracy <- sum(predictions == test_labels) / length(test_labels)
  return(accuracy)
}

```


Generating the random dataset and calling the functions
```{r}
# Function to simulate training and test datasets
simulate_datasets <- function(n_samples, n_test_samples, dim) {
  set.seed(123)
  train_data <- matrix(runif(n_samples * dim), ncol = dim)
  train_labels <- sample(c(0, 1), n_samples, replace = TRUE)
  
  test_data <- matrix(runif(n_test_samples * dim), ncol = dim)
  test_labels <- sample(c(0, 1), n_test_samples, replace = TRUE)
  
  return(list(train_data = train_data, train_labels = train_labels, test_data = test_data, test_labels = test_labels))
}

# Function to evaluate the classification accuracy for different sample sizes
evaluate_accuracy_with_sample_sizes <- function(dim, k_values, sample_sizes, n_test_samples) {
  for (n_samples in sample_sizes) {
    cat("Sample Size:", n_samples, "\n")
    
    # Simulate datasets
    datasets <- simulate_datasets(n_samples, n_test_samples, dim)
    
    for (k in k_values) {
      cat("Dimensions:", dim, "\n")
      cat("k:", k, "\n")
      
      # Measure the runtime
      start_time <- Sys.time()
      
      # Evaluate the accuracy
      accuracy <- evaluate_accuracy(datasets$train_data, datasets$train_labels, datasets$test_data, datasets$test_labels, k)
      
      # Print results
      cat("Accuracy:", accuracy, "\n")
      cat("Runtime:", round(difftime(Sys.time(), start_time, units = "secs"), 2), "seconds\n\n")
    }
  }
}

# Specify different sample sizes to test
sample_sizes <- c(100, 200, 300)

# Specify other parameters
dimensions <- c(10, 50, 1000)
k_values <- c(3, 5)

# Set the number of test samples
n_test_samples <- 50  # You can adjust this value based on your needs

# Testing the kNN algorithm with different sample sizes, feature dimensions, and k-values
for (dim in dimensions) {
  evaluate_accuracy_with_sample_sizes(dim, k_values, sample_sizes, n_test_samples)
}
```


Compare our function to the inbuilt class package
```{r}
# Function to perform kNN using the 'class' package
knn_class_package <- function(train_data, train_labels, test_data, k = 3) {
  predictions <- knn(train_data, test_data, train_labels, k = k)
  return(predictions)
}

# Function to evaluate the classification accuracy using the 'class' package
evaluate_accuracy_class_package <- function(train_data, train_labels, test_data, test_labels, k = 3) {
  predictions <- knn_class_package(train_data, train_labels, test_data, k)
  accuracy <- sum(predictions == test_labels) / length(test_labels)
  return(accuracy)
}

# Function to evaluate both custom kNN and 'class' package for comparison
compare_knn_implementations <- function(dim, k_values, sample_sizes) {
  for (n_samples in sample_sizes) {
    cat("Sample Size:", n_samples, "\n")
    
    # Simulate datasets
    datasets <- simulate_datasets(n_samples, n_test_samples, dim)
    
    for (k in k_values) {
      cat("Dimensions:", dim, "\n")
      cat("k:", k, "\n")
      
      # Measure the runtime and evaluate accuracy for custom kNN
      start_time_custom <- Sys.time()
      accuracy_custom <- evaluate_accuracy(datasets$train_data, datasets$train_labels, datasets$test_data, datasets$test_labels, k)
      cat("Custom kNN Accuracy:", accuracy_custom, "\n")
      cat("Custom kNN Runtime:", round(difftime(Sys.time(), start_time_custom, units = "secs"), 2), "seconds\n")
      
      # Evaluate accuracy for 'class' package kNN
      start_time_class <- Sys.time()
      accuracy_class <- evaluate_accuracy_class_package(datasets$train_data, datasets$train_labels, datasets$test_data, datasets$test_labels, k)
      cat("'class' Package kNN Accuracy:", accuracy_class, "\n")
      cat("'class' Package kNN Runtime:", round(difftime(Sys.time(), start_time_class, units = "secs"), 2), "seconds\n\n")
    }
  }
}

# Specify different sample sizes to test
sample_sizes <- c(100, 200, 300)

# Specify other parameters
dimensions <- c(10, 50, 1000)
k_values <- c(3, 5)

# Testing both custom kNN and 'class' package with different sample sizes, feature dimensions, and k-values
for (dim in dimensions) {
  compare_knn_implementations(dim, k_values, sample_sizes)
}

```
Improved version of our custom function, runtime is faster however still slower then the inbuilt package.
```{r}
# Optimized kNN implementation
knn_predict_optimized <- function(train_data, train_labels, test_point, k = 3, p = 2) {
  distances <- rowSums((train_data - test_point)^p)^(1/p)
  nearest_neighbors <- order(distances)[1:k]
  nearest_labels <- train_labels[nearest_neighbors]
  predicted_class <- as.numeric(names(sort(table(nearest_labels), decreasing = TRUE)[1]))
  return(predicted_class)
}

# Optimized function to evaluate classification accuracy
evaluate_accuracy_optimized <- function(train_data, train_labels, test_data, test_labels, k = 3) {
  predictions <- apply(test_data, 1, function(test_point) knn_predict_optimized(train_data, train_labels, test_point, k))
  accuracy <- sum(predictions == test_labels) / length(test_labels)
  return(accuracy)
}

# Function to evaluate both custom kNN and 'class' package for comparison
compare_knn_implementations_optimized <- function(dim, k_values, sample_sizes) {
  for (n_samples in sample_sizes) {
    cat("Sample Size:", n_samples, "\n")
    
    # Simulate datasets
    datasets <- simulate_datasets(n_samples, n_test_samples, dim)
    
    for (k in k_values) {
      cat("Dimensions:", dim, "\n")
      cat("k:", k, "\n")
      
      # Measure the runtime and evaluate accuracy for optimized custom kNN
      start_time_optimized <- Sys.time()
      accuracy_optimized <- evaluate_accuracy_optimized(datasets$train_data, datasets$train_labels, datasets$test_data, datasets$test_labels, k)
      cat("Optimized Custom kNN Accuracy:", accuracy_optimized, "\n")
      cat("Optimized Custom kNN Runtime:", round(difftime(Sys.time(), start_time_optimized, units = "secs"), 2), "seconds\n\n")
      
      # Evaluate accuracy for 'class' package kNN
      start_time_class <- Sys.time()
      accuracy_class <- evaluate_accuracy_class_package(datasets$train_data, datasets$train_labels, datasets$test_data, datasets$test_labels, k)
      cat("'class' Package kNN Accuracy:", accuracy_class, "\n")
      cat("'class' Package kNN Runtime:", round(difftime(Sys.time(), start_time_class, units = "secs"), 2), "seconds\n\n")
    }
  }
}

# Testing both optimized custom kNN and 'class' package with different sample sizes, feature dimensions, and k-values
for (dim in dimensions) {
  compare_knn_implementations_optimized(dim, k_values, sample_sizes)
}

```

Question 2:
```{r}
# Function to simulate training and test datasets
simulate_datasets <- function(n_samples, n_test_samples, dim) {
  set.seed(123)
  train_data <- matrix(runif(n_samples * dim), ncol = dim)
  train_labels <- sample(c(0, 1), n_samples, replace = TRUE)
  
  test_data <- matrix(runif(n_test_samples * dim), ncol = dim)
  test_labels <- sample(c(0, 1), n_test_samples, replace = TRUE)
  
  return(list(train_data = train_data, train_labels = train_labels, test_data = test_data, test_labels = test_labels))
}

# Modified kNN algorithm with random projection
knn_projected <- function(train_data, train_labels, test_data, k = 3, l = 5, p_norm = 2) {
  # Generate a random orthonormal matrix U of dimension l x p
  U <- randortho(ncol(train_data), l)
  
  # Project the training and test data onto the lower-dimensional space
  train_data_projected <- train_data %*% t(U)
  test_data_projected <- test_data %*% t(U)
  
  # Classify an input feature vector x according to the k-nearest neighbors in the lower-dimensional space
  knn_predict <- function(train_data, train_labels, test_point, k, p_norm) {
    distances <- apply(train_data, 1, function(train_point) sum(abs(train_point - test_point)^p_norm)^(1/p_norm))
    nearest_neighbors <- order(distances)[1:k]
    nearest_labels <- train_labels[nearest_neighbors]
    predicted_class <- as.numeric(names(sort(table(nearest_labels), decreasing = TRUE)[1]))
    return(predicted_class)
  }
  
  # Predict labels for test_data_projected
  predictions <- apply(test_data_projected, 1, function(test_point) knn_predict(train_data_projected, train_labels, test_point, k, p_norm))
  
  return(predictions)
}

# Function to evaluate the classification accuracy for different p-norms
evaluate_accuracy_projected <- function(train_data, train_labels, test_data, test_labels, k = 3, l = 5, p_norm = 2) {
  predictions <- knn_projected(train_data, train_labels, test_data, k, l, p_norm)
  accuracy <- sum(predictions == test_labels) / length(test_labels)
  return(accuracy)
}

# Function to compare the performance of the modified kNN algorithm with different p-norms
compare_knn_projected <- function(dim, k_values, sample_sizes, l_values, p_norms) {
  for (n_samples in sample_sizes) {
    cat("Sample Size:", n_samples, "\n")
    
    # Simulate datasets
    datasets <- simulate_datasets(n_samples, n_test_samples, dim)
    
    for (l in l_values) {
      cat("Lower Dimension (l):", l, "\n")
      
      for (p_norm in p_norms) {
        cat("p-Norm:", p_norm, "\n")
        
        for (k in k_values) {
          cat("k:", k, "\n")
          
          # Measure the runtime and evaluate accuracy for modified kNN
          start_time_projected <- Sys.time()
          accuracy_projected <- evaluate_accuracy_projected(datasets$train_data, datasets$train_labels, datasets$test_data, datasets$test_labels, k, l, p_norm)
          cat("Modified kNN Accuracy:", accuracy_projected, "\n")
          cat("Modified kNN Runtime:", round(difftime(Sys.time(), start_time_projected, units = "secs"), 2), "seconds\n\n")
        }
      }
    }
  }
}

# Specify parameters
sample_sizes <- c(100, 200, 300)
dimensions <- c(10, 50, 1000)
l_values <- c(2, 5)  # Adjust the lower dimension as needed
p_norms <- c(1, 2)   # Different p-norms

# Testing the modified kNN algorithm with random projection for different sample sizes, feature dimensions, lower dimensions, k-values, and p-norms
for (dim in dimensions) {
  compare_knn_projected(dim, k_values, sample_sizes, l_values, p_norms)
}

```
Problem 2 Version 2:
```{r}
# Function to generate a random orthonormal matrix
generate_random_orthonormal_matrix <- function(nrow, ncol) {
  Q <- qr.Q(qr(matrix(rnorm(nrow * ncol), nrow = nrow)))
  return(Q)
}

# Modified kNN algorithm with random projection
knn_projected <- function(train_data, train_labels, test_data, k = 3, l = 5, p_norm = 2) {
  # Generate a random orthonormal matrix U of dimension l x p
  U <- generate_random_orthonormal_matrix(ncol(train_data), l)
  
  # Project the training and test data onto the lower-dimensional space
  train_data_projected <- train_data %*% U
  test_data_projected <- test_data %*% U
  
  # Classify an input feature vector x according to the k-nearest neighbors in the lower-dimensional space
  knn_predict <- function(train_data, train_labels, test_point, k, p_norm) {
    distances <- apply(train_data, 1, function(train_point) sum(abs(train_point - test_point)^p_norm)^(1/p_norm))
    nearest_neighbors <- order(distances)[1:k]
    nearest_labels <- train_labels[nearest_neighbors]
    predicted_class <- as.numeric(names(sort(table(nearest_labels), decreasing = TRUE)[1]))
    return(predicted_class)
  }
  
  # Predict labels for test_data_projected
  predictions <- apply(test_data_projected, 1, function(test_point) knn_predict(train_data_projected, train_labels, test_point, k, p_norm))
  
  return(predictions)
}

# Function to compare the performance of the modified kNN algorithm with different p-norms
compare_knn_projected <- function(dim, k_values, sample_sizes, l_values, p_norms) {
  for (n_samples in sample_sizes) {
    cat("Sample Size:", n_samples, "\n")
    
    # Simulate datasets
    datasets <- simulate_datasets(n_samples, n_test_samples, dim)
    
    for (l in l_values) {
      cat("Lower Dimension (l):", l, "\n")
      
      for (p_norm in p_norms) {
        cat("p-Norm:", p_norm, "\n")
        
        for (k in k_values) {
          cat("k:", k, "\n")
          
          # Measure the runtime and evaluate accuracy for modified kNN
          start_time_projected <- Sys.time()
          accuracy_projected <- evaluate_accuracy_projected(datasets$train_data, datasets$train_labels, datasets$test_data, datasets$test_labels, k, l, p_norm)
          cat("Modified kNN Accuracy:", accuracy_projected, "\n")
          cat("Modified kNN Runtime:", round(difftime(Sys.time(), start_time_projected, units = "secs"), 2), "seconds\n\n")
        }
      }
    }
  }
}

# Testing the modified kNN algorithm with random projection for different sample sizes, feature dimensions, lower dimensions, k-values, and p-norms
for (dim in dimensions) {
  compare_knn_projected(dim, k_values, sample_sizes, l_values, p_norms)
}

```

